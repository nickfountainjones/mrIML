#' Wrapper to calculate performance metrics (Mathews correlation coefficient, sensitivity and specificity) for each model for each response variable.
#' @param yhats A \code{list} is the list generated by mrIMLpredicts
#' @param Model A \code{list}  the model used to generate the yhats object
#' @param Y  A \code{dataframe} is a response variable data set (species, SNPs etc).
#' @param mode \code{character}'classification' or 'regression' i.e., is the generative model a regression or classification?
#' @examples
#' \dontrun{
#' ModelPerf <- mrIMLperformance(yhats, Model = model1, Y = Y)
#' }
#'
#' @details Outputs a dataframe of commonly used metric that can be used to compare model performance of classification models. Performance metrics are based on testing data. But MCC is useful (higher numbers = better fit)
#'
#' @export

mrIMLperformance <- function(yhats, Model, Y, mode = "regression") {
  n_response <- length(yhats)
  mod_perf <- NULL
  bList <- yhats %>% purrr::map(pluck("last_mod_fit"))

  if (mode == "classification") {
    for (i in 1:n_response) {
      met1 <- as.data.frame(bList[[i]]$.metrics)
      roc <- met1$.estimate[2]
      yd <- as.data.frame(bList[[i]]$.predictions)
      mathews <- yardstick::mcc(yd, class, .pred_class)
      mathews <- mathews$.estimate
      sen <- yardstick::sens(yd, class, .pred_class)
      sen <- sen$.estimate
      spe <- yardstick::spec(yd, class, .pred_class)
      ppv_e <- yardstick::ppv(yd, class, .pred_class)
      ppv <- ppv_e$.estimate
      spe <- spe$.estimate
      mod_name <- class(Model)[1]
      sp <- names(Y[i])
      prev <- sum(Y[i]) / nrow(Y)
      mod_perf[[i]] <- c(
        sp, mod_name, roc, mathews, sen,
        spe, ppv, prev
      )
    }
    mod1_perf <- do.call(rbind, mod_perf)
    mod1_perf <- as.data.frame(mod1_perf)
    colnames(mod1_perf) <- c(
      "response", "model_name",
      "roc_AUC", "mcc", "sensitivity", "ppv",
      "specificity", "prevalence"
    )
    Global_summary <- as.numeric(as.character(unlist(mod1_perf$mcc)))
    Global_summary[is.na(Global_summary)] <- 0
    Global_summary <- mean(Global_summary)
  }
  if (mode == "regression") {
    for (i in 1:n_response) {
      met1 <- as.data.frame(bList[[i]]$.metrics)
      rmse <- met1$.estimate[1]
      rsq <- met1$.estimate[2]
      mod_name <- class(Model)[1]
      sp <- names(Y[i])
      mod_perf[[i]] <- data.frame(sp, mod_name, rmse, rsq)
    }
    mod1_perf <- do.call(rbind, mod_perf)
    mod1_perf <- as.data.frame(mod1_perf)
    colnames(mod1_perf) <- c(
      "response", "model_name",
      "rmse", "rsquared"
    )
    Global_summary <- as.numeric(as.character(unlist(mod1_perf$rmse)))
    Global_summary <- mean(Global_summary, na.rm = TRUE)
  }
  return(list(mod1_perf, Global_summary))
}
